<!DOCTYPE html>
<html lang="ja">

<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1.0">
	<title>遅延</title>
	<style>
		#canvas,
		#view1 {
			width: 100%;
			height: 100%;
		}

		#canvas,
		#video {
			visibility: hidden;
			opacity: 0;
		}

		.hiddenWrapper {
			visibility: hidden;
			overflow: hidden;
			height: 0;
			width: 0;
		}
	</style>
	<script src="https://webrtc.github.io/adapter/adapter-latest.js"></script>
</head>

<body>
	<div>
		<h1>遅延映像</h1>
		<p>遅延時間(s)<input type="number" name="delay" id="delay" min="1" max="20" value="5" /></p>
		<p>カメラ選択
			<select name="" id="cameraSelect" class="select">
				<option value="">Select camera</option>
			</select>
		</p>
		<canvas id="view1"></canvas>
		<div class="hiddenWrapper">
			<video id="video"></video>
			<canvas id="canvas" style="display: block;"></canvas>
		</div>
	</div>
	<script>
		'use strict';
		let DRAYTIME = 5;
		const FPS = 16;
		const video = document.getElementById("video");
		const canvas = document.querySelector("#canvas");
		const view1 = document.querySelector("#view1");
		const cameraOptions = document.querySelector('#cameraSelect');
		const context2d = canvas.getContext("2d");
		let count = 0;
		let intervalID = null;
		//スマホ対策
		video.setAttribute('autoplay', '');
		video.setAttribute('muted', '');
		video.setAttribute('playsinline', '');
		const drowView = () => {
			const Mem = Array(2 ** Math.round(Math.log2(DRAYTIME * FPS)));
			if (intervalID !== null) {
				clearInterval(intervalID);
			}
			intervalID = setInterval(() => {
				view1.width = canvas.width = video.clientWidth;
				view1.height = canvas.height = video.clientHeight;
				const vcRatio = canvas.clientWidth / video.clientWidth;
				context2d.drawImage(video, 0, 0, video.clientWidth, video.clientHeight);
				Mem[count & (Mem.length - 1)] = context2d.getImageData(0, 0, video.clientWidth, video.clientHeight);
				if (Mem[(count + 1) & (Mem.length - 1)] != undefined) {
					view1.getContext('2d').putImageData(Mem[(count + 1) & (Mem.length - 1)], 0, 0);
				}
				if (count >= Mem.length) {
					count = 0;
				} else {
					count++;
				}
			}, 1000 / FPS);
		};
		const MediaArgs = {
			video: true,
			audio: false,
		};
		const start = async (args) => {
			await navigator.mediaDevices.getUserMedia(args).then(stream => {
				video.srcObject = stream;
				video.play();
				drowView();
				init();
			}).catch(e => {
				console.log(e)
			});
		};
		const init = async () => {
			if (!navigator.mediaDevices?.enumerateDevices) {
				console.log("enumerateDevices() not supported.");
			} else {
				const devices = await navigator.mediaDevices.enumerateDevices();
				const videoDevices = devices.filter((device) => device.kind === 'videoinput');
				videoDevices.forEach((device) => {
					console.log(device);
					console.log(`${device.kind}: ${device.label} id = ${device.deviceId}`);
				});

				if (videoDevices.length > 1 && videoDevices.every(d => d.deviceId != '')) {
					cameraOptions.innerHTML = "";
					for (let i = 0; i < videoDevices.length; i++) {
						const videoDevice = videoDevices[i];
						const option = document.createElement('option');
						option.value = videoDevice.deviceId;
						option.text = videoDevice.label || `camera:${i + 1}`
						cameraOptions.appendChild(option);
					}

				}

			}
		};
		init().then(() => start(MediaArgs))
		//イベント
		document.getElementById("delay").oninput = (e) => {
			DRAYTIME = e.target.value;
			drowView();
		};
		document.getElementById("cameraSelect").onchange = (e) => {
			MediaArgs.video = {
				deviceId: e.target.value
			};
			console.log("select");
			start(MediaArgs);
		};

	</script>

</body>

</html>